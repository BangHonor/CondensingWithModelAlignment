Namespace(gpu_id=2, dataset='ogbn-arxiv', dis_metric='ours', epochs=1000, nlayers=0, hidden=256, lr_adj=0.01, lr_feat=0.01, lr_model=0.01, weight_decay=0.0, dropout=0.5, normalize_features=True, keep_ratio=1.0, reduction_rate=0.1, seed=1, alpha=0, debug=0, sgc=1, inner=10, outer=20, save=1, model='GCN')
pyg_data: Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343, nnz=1166243])
split_index: {'train': tensor([     0,      1,      2,  ..., 169145, 169148, 169251]), 'valid': tensor([   349,    357,    366,  ..., 169185, 169261, 169296]), 'test': tensor([   346,    398,    451,  ..., 169340, 169341, 169342])}
WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.5.
train val test的长度: 90941 29799 48603
size of adj_train: (90941, 90941)
edges in adj_train: 738066.0
/home/xzb/GCond/gcond_agent_transduct.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1656352660876/work/torch/csrc/utils/tensor_new.cpp:201.)
  indices = torch.tensor([np.arange(n), np.arange(n)], dtype=torch.int64)
adj_syn: (9078, 9078) feat_syn: torch.Size([9078, 128])
开始图凝聚！
epoch: 0
Epoch 0, 梯度匹配loss_avg: 26.544158325195312
Train set results: loss= 2.4745 accuracy= 0.4575
Test set results: loss= 2.6145 accuracy= 0.4625
epoch: 1
epoch: 2
epoch: 3
epoch: 4
epoch: 5
epoch: 6
epoch: 7
epoch: 8
epoch: 9
epoch: 10
epoch: 11
epoch: 12
epoch: 13
epoch: 14
epoch: 15
epoch: 16
epoch: 17
epoch: 18
epoch: 19
epoch: 20
epoch: 21
epoch: 22
epoch: 23
epoch: 24
epoch: 25
epoch: 26
epoch: 27
epoch: 28
epoch: 29
epoch: 30
epoch: 31
epoch: 32
epoch: 33
epoch: 34
epoch: 35
epoch: 36
epoch: 37
epoch: 38
epoch: 39
epoch: 40
epoch: 41
epoch: 42
epoch: 43
epoch: 44
epoch: 45
epoch: 46
epoch: 47
epoch: 48
epoch: 49
epoch: 50
epoch: 51
epoch: 52
epoch: 53
epoch: 54
epoch: 55
epoch: 56
epoch: 57
epoch: 58
epoch: 59
epoch: 60
epoch: 61
epoch: 62
epoch: 63
epoch: 64
epoch: 65
epoch: 66
epoch: 67
epoch: 68
epoch: 69
epoch: 70
epoch: 71
epoch: 72
epoch: 73
epoch: 74
epoch: 75
epoch: 76
epoch: 77
epoch: 78
epoch: 79
epoch: 80
epoch: 81
epoch: 82
epoch: 83
epoch: 84
epoch: 85
epoch: 86
epoch: 87
epoch: 88
epoch: 89
epoch: 90
epoch: 91
epoch: 92
epoch: 93
epoch: 94
epoch: 95
epoch: 96
epoch: 97
epoch: 98
epoch: 99
epoch: 100
Epoch 100, 梯度匹配loss_avg: 2.232371597290039
Train set results: loss= 1.2523 accuracy= 0.6490
Test set results: loss= 1.2383 accuracy= 0.6360
epoch: 101
epoch: 102
epoch: 103
epoch: 104
epoch: 105
epoch: 106
epoch: 107
epoch: 108
epoch: 109
epoch: 110
epoch: 111
epoch: 112
epoch: 113
epoch: 114
epoch: 115
epoch: 116
epoch: 117
epoch: 118
epoch: 119
epoch: 120
epoch: 121
epoch: 122
epoch: 123
epoch: 124
epoch: 125
epoch: 126
epoch: 127
epoch: 128
epoch: 129
epoch: 130
epoch: 131
epoch: 132
epoch: 133
epoch: 134
epoch: 135
epoch: 136
epoch: 137
epoch: 138
epoch: 139
epoch: 140
epoch: 141
epoch: 142
epoch: 143
epoch: 144
epoch: 145
epoch: 146
epoch: 147
epoch: 148
epoch: 149
epoch: 150
epoch: 151
epoch: 152
epoch: 153
epoch: 154
epoch: 155
epoch: 156
epoch: 157
epoch: 158
epoch: 159
epoch: 160
epoch: 161
epoch: 162
epoch: 163
epoch: 164
epoch: 165
epoch: 166
epoch: 167
epoch: 168
epoch: 169
epoch: 170
epoch: 171
epoch: 172
epoch: 173
epoch: 174
epoch: 175
epoch: 176
epoch: 177
epoch: 178
epoch: 179
epoch: 180
epoch: 181
epoch: 182
epoch: 183
epoch: 184
epoch: 185
epoch: 186
epoch: 187
epoch: 188
epoch: 189
epoch: 190
epoch: 191
epoch: 192
epoch: 193
epoch: 194
epoch: 195
epoch: 196
epoch: 197
epoch: 198
epoch: 199
epoch: 200
Epoch 200, 梯度匹配loss_avg: 1.791229248046875
Train set results: loss= 1.3298 accuracy= 0.6585
Test set results: loss= 1.4003 accuracy= 0.6442
epoch: 201
epoch: 202
epoch: 203
epoch: 204
epoch: 205
epoch: 206
epoch: 207
epoch: 208
epoch: 209
epoch: 210
epoch: 211
epoch: 212
epoch: 213
epoch: 214
epoch: 215
epoch: 216
epoch: 217
epoch: 218
epoch: 219
epoch: 220
epoch: 221
epoch: 222
epoch: 223
epoch: 224
epoch: 225
epoch: 226
epoch: 227
epoch: 228
epoch: 229
epoch: 230
epoch: 231
epoch: 232
epoch: 233
epoch: 234
epoch: 235
epoch: 236
epoch: 237
epoch: 238
epoch: 239
epoch: 240
epoch: 241
epoch: 242
epoch: 243
epoch: 244
epoch: 245
epoch: 246
epoch: 247
epoch: 248
epoch: 249
epoch: 250
epoch: 251
epoch: 252
epoch: 253
epoch: 254
epoch: 255
epoch: 256
epoch: 257
epoch: 258
epoch: 259
epoch: 260
epoch: 261
epoch: 262
epoch: 263
epoch: 264
epoch: 265
epoch: 266
epoch: 267
epoch: 268
epoch: 269
epoch: 270
epoch: 271
epoch: 272
epoch: 273
epoch: 274
epoch: 275
epoch: 276
epoch: 277
epoch: 278
epoch: 279
epoch: 280
epoch: 281
epoch: 282
epoch: 283
epoch: 284
epoch: 285
epoch: 286
epoch: 287
epoch: 288
epoch: 289
epoch: 290
epoch: 291
epoch: 292
epoch: 293
epoch: 294
epoch: 295
epoch: 296
epoch: 297
epoch: 298
epoch: 299
epoch: 300
Epoch 300, 梯度匹配loss_avg: 1.8235142135620117
Train set results: loss= 1.3663 accuracy= 0.6656
Test set results: loss= 1.4661 accuracy= 0.6568
epoch: 301
epoch: 302
epoch: 303
epoch: 304
epoch: 305
epoch: 306
epoch: 307
epoch: 308
epoch: 309
epoch: 310
epoch: 311
epoch: 312
epoch: 313
epoch: 314
epoch: 315
epoch: 316
epoch: 317
epoch: 318
epoch: 319
epoch: 320
epoch: 321
epoch: 322
epoch: 323
epoch: 324
epoch: 325
epoch: 326
epoch: 327
epoch: 328
epoch: 329
epoch: 330
epoch: 331
epoch: 332
epoch: 333
epoch: 334
epoch: 335
epoch: 336
epoch: 337
epoch: 338
epoch: 339
epoch: 340
epoch: 341
epoch: 342
epoch: 343
epoch: 344
epoch: 345
epoch: 346
epoch: 347
epoch: 348
epoch: 349
epoch: 350
epoch: 351
epoch: 352
epoch: 353
epoch: 354
epoch: 355
epoch: 356
epoch: 357
epoch: 358
epoch: 359
epoch: 360
epoch: 361
epoch: 362
epoch: 363
epoch: 364
epoch: 365
epoch: 366
epoch: 367
epoch: 368
epoch: 369
epoch: 370
epoch: 371
epoch: 372
epoch: 373
epoch: 374
epoch: 375
epoch: 376
epoch: 377
epoch: 378
epoch: 379
epoch: 380
epoch: 381
epoch: 382
epoch: 383
epoch: 384
epoch: 385
epoch: 386
epoch: 387
epoch: 388
epoch: 389
epoch: 390
epoch: 391
epoch: 392
epoch: 393
epoch: 394
epoch: 395
epoch: 396
epoch: 397
epoch: 398
epoch: 399
epoch: 400
Epoch 400, 梯度匹配loss_avg: 1.742815933227539
Train set results: loss= 1.4410 accuracy= 0.6652
Test set results: loss= 1.5743 accuracy= 0.6464
epoch: 401
epoch: 402
epoch: 403
epoch: 404
epoch: 405
epoch: 406
epoch: 407
epoch: 408
epoch: 409
epoch: 410
epoch: 411
epoch: 412
epoch: 413
epoch: 414
epoch: 415
epoch: 416
epoch: 417
epoch: 418
epoch: 419
epoch: 420
epoch: 421
epoch: 422
epoch: 423
epoch: 424
epoch: 425
epoch: 426
epoch: 427
epoch: 428
epoch: 429
epoch: 430
epoch: 431
epoch: 432
epoch: 433
epoch: 434
epoch: 435
epoch: 436
epoch: 437
epoch: 438
epoch: 439
epoch: 440
epoch: 441
epoch: 442
epoch: 443
epoch: 444
epoch: 445
epoch: 446
epoch: 447
epoch: 448
epoch: 449
epoch: 450
epoch: 451
epoch: 452
epoch: 453
epoch: 454
epoch: 455
epoch: 456
epoch: 457
epoch: 458
epoch: 459
epoch: 460
epoch: 461
epoch: 462
epoch: 463
epoch: 464
epoch: 465
epoch: 466
epoch: 467
epoch: 468
epoch: 469
epoch: 470
epoch: 471
epoch: 472
epoch: 473
epoch: 474
epoch: 475
epoch: 476
epoch: 477
epoch: 478
epoch: 479
epoch: 480
epoch: 481
epoch: 482
epoch: 483
epoch: 484
epoch: 485
epoch: 486
epoch: 487
epoch: 488
epoch: 489
epoch: 490
epoch: 491
epoch: 492
epoch: 493
epoch: 494
epoch: 495
epoch: 496
epoch: 497
epoch: 498
epoch: 499
epoch: 500
Epoch 500, 梯度匹配loss_avg: 1.76419921875
Train set results: loss= 1.6415 accuracy= 0.6459
Test set results: loss= 1.8179 accuracy= 0.6444
epoch: 501
epoch: 502
epoch: 503
epoch: 504
epoch: 505
epoch: 506
epoch: 507
epoch: 508
epoch: 509
epoch: 510
epoch: 511
epoch: 512
epoch: 513
epoch: 514
epoch: 515
epoch: 516
epoch: 517
epoch: 518
epoch: 519
epoch: 520
epoch: 521
epoch: 522
epoch: 523
epoch: 524
epoch: 525
epoch: 526
epoch: 527
epoch: 528
epoch: 529
epoch: 530
epoch: 531
epoch: 532
epoch: 533
epoch: 534
epoch: 535
epoch: 536
epoch: 537
epoch: 538
epoch: 539
epoch: 540
epoch: 541
epoch: 542
epoch: 543
epoch: 544
epoch: 545
epoch: 546
epoch: 547
epoch: 548
epoch: 549
epoch: 550
epoch: 551
epoch: 552
epoch: 553
epoch: 554
epoch: 555
epoch: 556
epoch: 557
epoch: 558
epoch: 559
epoch: 560
epoch: 561
epoch: 562
epoch: 563
epoch: 564
epoch: 565
epoch: 566
epoch: 567
epoch: 568
epoch: 569
epoch: 570
epoch: 571
epoch: 572
epoch: 573
epoch: 574
epoch: 575
epoch: 576
epoch: 577
epoch: 578
epoch: 579
epoch: 580
epoch: 581
epoch: 582
epoch: 583
epoch: 584
epoch: 585
epoch: 586
epoch: 587
epoch: 588
epoch: 589
epoch: 590
epoch: 591
epoch: 592
epoch: 593
epoch: 594
epoch: 595
epoch: 596
epoch: 597
epoch: 598
epoch: 599                       
epoch: 600
Epoch 600, 梯度匹配loss_avg: 1.6403168106079102
Train set results: loss= 1.6861 accuracy= 0.6516
Test set results: loss= 1.8369 accuracy= 0.6470
epoch: 601
epoch: 602
epoch: 603
epoch: 604
epoch: 605
epoch: 606
epoch: 607
epoch: 608
epoch: 609
epoch: 610
epoch: 611
epoch: 612
epoch: 613
epoch: 614
epoch: 615
epoch: 616
epoch: 617
epoch: 618
epoch: 619
epoch: 620
epoch: 621
epoch: 622
epoch: 623
epoch: 624
epoch: 625
epoch: 626
epoch: 627
epoch: 628
epoch: 629
epoch: 630
epoch: 631
epoch: 632
epoch: 633
epoch: 634
epoch: 635
epoch: 636
epoch: 637
epoch: 638
epoch: 639
epoch: 640
epoch: 641
epoch: 642
epoch: 643
epoch: 644
epoch: 645
epoch: 646
epoch: 647
epoch: 648
epoch: 649
epoch: 650
epoch: 651
epoch: 652
epoch: 653
epoch: 654
epoch: 655
epoch: 656
epoch: 657
